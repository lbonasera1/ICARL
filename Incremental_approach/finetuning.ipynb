{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qF9tU2o82w7j"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAgq9DaM22RC"
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.RandomCrop(32,padding=4),\n",
    "                                          torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "                                          torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "aVpjX02f3BR_",
    "outputId": "ab764199-d770-4830-91b6-efdcded8011e"
   },
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.CIFAR100(root='./ICARL/data', download = True, transform = transform, target_transform = None)\n",
    "data_test = torchvision.datasets.CIFAR100(root='./ICARL/data',train = False,download = True, transform = torchvision.transforms.ToTensor(), target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r7qVZwiPe-l"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "Credits to @hshustc\n",
    "Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        self.inplanes = 16\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        ###### self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "        self.fc = nn.ModuleList([nn.Linear(64,10)])\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def updatemodel(self):\n",
    "        self.fc.append(nn.Linear(64,10).cuda())\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        t = x\n",
    "        x = self.fc[0](x)\n",
    "        for i in range(1,len(self.fc)):\n",
    "            x = torch.cat((x,self.fc[i](t)),1)\n",
    "        return x\n",
    "\n",
    "def resnet32(pretrained=False, **kwargs):\n",
    "    n = 5\n",
    "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0lZunBS3NhD"
   },
   "outputs": [],
   "source": [
    "def obtain_list_of_subset(seed,dataset):\n",
    "    l = list(range(0,100))\n",
    "    random.Random(seed).shuffle(l)\n",
    "    dc = {tuple(l[i:i+10]) : [] for i in range(0,100,10)}\n",
    "    for i,t in enumerate(dataset.targets):\n",
    "        idx = [j for j in range(10) if  t in list(dc.keys())[j]]\n",
    "        dc[list(dc.keys())[idx[0]]].append(i)\n",
    "    return list(dc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z14-93Ui3QXW"
   },
   "outputs": [],
   "source": [
    "### this function create a mapping beetwen the real label of the class and their adaptation based \n",
    "### on the batch their are introduced\n",
    "def new_label2(label, index, target_t_old = None):\n",
    "    if target_t_old is None:\n",
    "        if  not isinstance(label,list):\n",
    "            label = label.tolist()\n",
    "        target_t = tuple(set(label))\n",
    "        return target_t, [(target_t.index(el) + index) for el in label]\n",
    "    else:  \n",
    "        return target_t_old, [(target_t_old.index(el) + index) for el in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVYFBTy33TTA"
   },
   "outputs": [],
   "source": [
    "## this function create a tensor that is used in order to correctly compute the loss\n",
    "def crea_target_finetuning(BatchDati,Target,C):\n",
    "    N = BatchDati.size(0)\n",
    "    C = C\n",
    "    NewTarget = torch.zeros(N,C)\n",
    "    for i in range(N):\n",
    "        NewTarget[i,Target[i]] = 1\n",
    "    return NewTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1gOMjjg3WQK"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOb8aHM13YIf"
   },
   "outputs": [],
   "source": [
    "### return the value of the accuracy over the test dataset\n",
    "def accuracy(test_data, model, label):\n",
    "    classi_finali = []\n",
    "    dl1 = torch.utils.data.DataLoader(test_data, batch_size = 128)\n",
    "    for input_data, _  in dl1:\n",
    "      input_data = input_data.to(DEVICE)\n",
    "      output = model(input_data)\n",
    "      del input_data\n",
    "      torch.cuda.empty_cache()\n",
    "      _, classes = torch.max(output,1)\n",
    "      del output\n",
    "      torch.cuda.empty_cache()\n",
    "      classes = classes.tolist()\n",
    "      classi_finali = classi_finali + classes\n",
    "    corretti = 0\n",
    "    for i in range(len(classi_finali)):\n",
    "        if classi_finali[i] == label[i]:\n",
    "            corretti = corretti + 1\n",
    "\n",
    "    return corretti/len(classi_finali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzDYI6yz4l2J"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "model_distillation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2K08szP3LKuy",
    "outputId": "7ad25291-9b4b-4362-faae-1e70c9eaba62"
   },
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "  del model\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "from torch.backends import cudnn\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "model = resnet32()\n",
    "model = model.to(DEVICE)\n",
    "cudnn.benchmark\n",
    "\n",
    "list_of_image = obtain_list_of_subset(1992,data_train)\n",
    "list_of_image_test = obtain_list_of_subset(1992,data_test)\n",
    "test = None\n",
    "test_label = []\n",
    "accuracy_test = []\n",
    "for i in range(10):\n",
    "    data = torch.utils.data.Subset(data_train,list_of_image[i])\n",
    "    if i == 0:\n",
    "      optimizer = torch.optim.SGD(model.parameters(),lr=2)\n",
    "    else:\n",
    "      optimizer = torch.optim.SGD(model.fc[i].parameters(),lr=2)\n",
    "\n",
    "    scheduler =torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones =  [49,63], gamma=0.2, last_epoch=-1)\n",
    "    \n",
    "    dl = torch.utils.data.DataLoader(data,batch_size=128, num_workers = 4)\n",
    "        \n",
    "    LR = 2\n",
    "    EPOCHS = 70\n",
    "    target_t_old = None\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "      counter = 0\n",
    "      for   images, label in (dl):\n",
    "            \n",
    "            images = images.to(DEVICE)\n",
    "            \n",
    "            labels = label.to(DEVICE)\n",
    "            \n",
    "            output = model(images)\n",
    "            output = output.to(DEVICE)\n",
    "            target_t_old, new_target = new_label2(label, i*10, target_t_old)\n",
    "            target_loss = crea_target_finetuning(images, new_target,i*10 + 10)\n",
    "            target_loss = target_loss.to(DEVICE)\n",
    "            loss_value = loss_function(output,target_loss)\n",
    "            if counter % 39 == 0 and counter != 0:\n",
    "              print(\"epoch:\",epoch,\"loss\",loss_value,\"lr\",scheduler.get_last_lr())\n",
    "            counter = counter + 1\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            del output\n",
    "            del images\n",
    "            del label\n",
    "            torch.cuda.empty_cache()\n",
    "      scheduler.step()\n",
    "    \n",
    "    print(\"entro in modalit√† test\")\n",
    "    model.eval()\n",
    "    if test is None:\n",
    "        test = torch.utils.data.Subset(data_test,list_of_image_test[i])\n",
    "        target = [label for _, label in test]\n",
    "        _, label = new_label2(target, i*10, target_t_old)\n",
    "        test_label = test_label + label\n",
    "        accuracy_test.append(accuracy(test, model, test_label))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        subset = torch.utils.data.Subset(data_test,list_of_image_test[i])\n",
    "        test = torch.utils.data.ConcatDataset([test,subset])\n",
    "        target = [label for _, label in subset]\n",
    "        _, label = new_label2(target, i*10, target_t_old)\n",
    "        test_label = test_label + label\n",
    "        accuracy_test.append(accuracy(test, model, test_label))\n",
    "    print(target_loss.size())\n",
    "    print(loss_value, epoch)\n",
    "    del target_loss\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"accuracy:\",accuracy_test[i])    \n",
    "    model.updatemodel()\n",
    "    print(\"model update\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "finetuningrisultati.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
