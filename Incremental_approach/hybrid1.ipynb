{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hybridgiustino.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mnQ_pGrkDXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.backends import cudnn\n",
        "from torchvision.datasets import CIFAR100\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akEbvR1RkMAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\"\"\"\n",
        "Credits to @hshustc\n",
        "Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        self.flag = True\n",
        "        self.inplanes = 16\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)  #### verificare il bias \n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "        ###### self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "        self.fc = nn.ModuleList([nn.Linear(64,10)])\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    \n",
        "    def updatemodel(self):\n",
        "        self.fc.append(nn.Linear(64,10).cuda())\n",
        "\n",
        "    def set_flag(self,b):\n",
        "        self.flag = b\n",
        "      \n",
        "              \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        if self.flag == False:\n",
        "          return x\n",
        "        else:\n",
        "          t = x\n",
        "          x = self.fc[0](x)\n",
        "          for i in range(1,len(self.fc)):\n",
        "            x = torch.cat((x,self.fc[i](t)),1)\n",
        "        return x\n",
        "\n",
        "def resnet32(pretrained=False, **kwargs):\n",
        "    n = 5\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Nj6aVwliju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = torchvision.transforms.Compose([torchvision.transforms.RandomCrop(32,padding=4),\n",
        "                                          torchvision.transforms.RandomHorizontalFlip(0.5),\n",
        "                                          torchvision.transforms.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hraFlm-lUQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir('./ICARL'):\n",
        "  !git clone https://github.com/lbonasera1/ICARL.git\n",
        "data_train = CIFAR100(root='./ICARL/data', train=True, download=True, transform=transform)\n",
        "data_test = CIFAR100(root='./ICARL/data', train=False, download=True, transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVV8nybvkZXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obtain_list_of_subset(seed,dataset):\n",
        "    l = list(range(0,100))\n",
        "    random.Random(seed).shuffle(l)\n",
        "    dc = {tuple(l[i:i+10]) : [] for i in range(0,100,10)}\n",
        "    for i,t in enumerate(dataset.targets):\n",
        "        #print(i,t)\n",
        "        idx = [j for j in range(10) if  t in list(dc.keys())[j]]\n",
        "        dc[list(dc.keys())[idx[0]]].append(i)\n",
        "    return list(dc.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NfskH19kfl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_data, model, label):\n",
        "    classi_finali = []\n",
        "    dl1 = torch.utils.data.DataLoader(test_data, batch_size = 128)\n",
        "    for input_data, _  in dl1:\n",
        "      input_data = input_data.to(DEVICE)\n",
        "      output = model(input_data)\n",
        "      del input_data\n",
        "      torch.cuda.empty_cache()\n",
        "      _, classes = torch.max(output,1)\n",
        "      del output\n",
        "      torch.cuda.empty_cache()\n",
        "      classes = classes.tolist()\n",
        "      classi_finali = classi_finali + classes\n",
        "    corretti = 0\n",
        "    for i in range(len(classi_finali)):\n",
        "        if classi_finali[i] == label[i]:\n",
        "            corretti = corretti + 1\n",
        "\n",
        "    return corretti/len(classi_finali)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mp5l9u5kjXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_label2(label, index, target_t_old = None):\n",
        "    if target_t_old is None:\n",
        "        if  not isinstance(label,list):\n",
        "            label = label.tolist()\n",
        "        target_t = tuple(set(label))\n",
        "        return target_t, [(target_t.index(el) + index) for el in label]\n",
        "    else:  ### in questo caso ho gi√†  i vecchi indici e i nuovi associati\n",
        "        return target_t_old, [(target_t_old.index(el) + index) for el in label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLijpza8kpgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_label_exemplar(label, target_t_prec, target_t_old, index): ### label sono le etichette del codice\n",
        "    new_target = []\n",
        "    old_class_set = set([item for sublist in target_t_prec for item in sublist])\n",
        "    \n",
        "    if target_t_old is None:\n",
        "        if  not isinstance(label,list):\n",
        "            label = label.tolist()\n",
        "        target_t_old = tuple(set(label)-old_class_set)\n",
        "    \n",
        "    for i,el in enumerate(label):\n",
        "       \n",
        "        if el in target_t_old:\n",
        "            \n",
        "            new_target.append(target_t_old.index(el) + index*10)\n",
        "\n",
        "        else:\n",
        "            for j,t in enumerate(target_t_prec):\n",
        "                if el in t:\n",
        "                    new_target.append(t.index(el) + (j*10))\n",
        "                    \n",
        "    return target_t_old,new_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPZPr5rnkqPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crea_target_classification(BatchDati,Target,i):\n",
        "    N = BatchDati.size(0)\n",
        "    C = i*10+10\n",
        "    NewTarget = torch.zeros(N,C)\n",
        "    for j in range(N):\n",
        "        if Target[j] >= i*10 and Target[j] < (i+1)*10:  ### sono nelle classi correnti\n",
        "            NewTarget[j,Target[j]] = 1 \n",
        "    return NewTarget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axf-vRGjks5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crea_target_distillation(output_distillation):\n",
        "    output_distillation = torch.sigmoid(output_distillation)\n",
        "    N = output_distillation.size(0)\n",
        "    zero_tensor = torch.zeros(N,10).to(DEVICE)\n",
        "    output_distillation = torch.cat((output_distillation, zero_tensor),1)\n",
        "    return output_distillation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpOTtWsWkvmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crea_label_classification_distillation(label_distillation, label_classification):\n",
        "    return label_distillation+label_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM8oMS4sk105",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take_index_for_class(data):\n",
        "    target = [el[1] for el in data]\n",
        "    target = tuple(set(target))\n",
        "    dc = {k:[] for k in target}\n",
        "    for i,el in enumerate(data):\n",
        "        (dc[el[1]]).append(i)\n",
        "    return dc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SQfbdLVk2aH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduceExemplars(exemplars, classes, m):\n",
        "    for c in classes:\n",
        "      exemplars[c] = exemplars[c][:m]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3xg2EJfk4Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def constructExemplar(exemplars,data,classi,classindex,model,m):\n",
        "    # model.eval()\n",
        "    class_means = torch.empty((0, 64)).cuda()\n",
        "    with torch.no_grad():\n",
        "        model.set_flag(False)\n",
        "        print(\"classi:\",classi)\n",
        "        for c in classi:\n",
        "            print(\"classe: \",c)\n",
        "            features = torch.empty(0,64).to('cuda')\n",
        "            indexes = copy.deepcopy(classindex[c])\n",
        "            subset = torch.utils.data.Subset(data,indexes)\n",
        "            dataloader = torch.utils.data.DataLoader(subset,batch_size = 128)\n",
        "\n",
        "            for image, label in dataloader:\n",
        "                image = image.to('cuda')\n",
        "                output = model(image)\n",
        "                output = nn.functional.normalize(output, p=2, dim=1)\n",
        "                features = torch.cat((features,output))\n",
        "                \n",
        "            \n",
        "            class_mean = torch.mean(features, 0)\n",
        "            class_mean = nn.functional.normalize(class_mean, p=2, dim=0)\n",
        "            class_mean = class_mean.view(-1, 64)\n",
        "            class_means = torch.cat((class_means, class_mean))\n",
        "            current_features = torch.empty((0, 64)).cuda()\n",
        "            exemplars_indexes = []\n",
        "            for k in range(m):\n",
        "              current_sum = torch.sum(current_features, 0)\n",
        "              current_sum = torch.add(features, current_sum.repeat(features.size(0), 1))\n",
        "              current_mean = current_sum * (1.0/(k+1))\n",
        "              current_mean = nn.functional.normalize(current_mean, p=2, dim=1)\n",
        "              distances = torch.empty((1, 0)).cuda()\n",
        "              for n in range(features.size(0)):\n",
        "                dist = torch.dist(current_mean[n], class_mean, p=2)\n",
        "                dist = dist.view(1, 1)\n",
        "                distances = torch.cat((distances, dist), 1)\n",
        "              index = torch.argmin(distances).item()   \n",
        "              phi = features[index].view(-1, 64)\n",
        "              # collecting chosen features\n",
        "              current_features = torch.cat((current_features, phi))\n",
        "              # removing chosen features\n",
        "              features = torch.cat((features[:index], features[index+1:]))\n",
        "              exemplars_indexes.append(indexes.pop(index)) \n",
        "            exemplars[c] = exemplars_indexes\n",
        "    model.set_flag(True)\n",
        "    return class_means"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWbewaWZk7oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = None\n",
        "model_distillation = None\n",
        "DEVICE = 'cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ux9Albk-4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU1N9g8zlAgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_printoptions(threshold=5000)\n",
        "import random\n",
        "if model is not None:\n",
        "  del model\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "if model_distillation is not None: \n",
        "  del model_distillation\n",
        "  torch.cuda.empty_cache()\n",
        "  model_distillation = None\n",
        "\n",
        "from torch.backends import cudnn\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "model = resnet32()\n",
        "model = model.to(DEVICE)\n",
        "cudnn.benchmark\n",
        "\n",
        "list_of_image = obtain_list_of_subset(1992,data_train)\n",
        "list_of_image_test = obtain_list_of_subset(1992,data_test)\n",
        "dc = take_index_for_class(data_train)\n",
        "test = None\n",
        "test_label = []\n",
        "accuracy_test = []\n",
        "exemplars = [[] for x in range(100)]\n",
        "target_prec = []\n",
        "M = 2000\n",
        "for i in range(10):\n",
        "    a = set(([item for sublist in exemplars for item in sublist]))\n",
        "    somma= sum([1 for el in  a])\n",
        "    print(\"num exemplari:\",somma)\n",
        "    l = list_of_image[i]+[item for sublist in exemplars for item in sublist]\n",
        "    random.Random(1992).shuffle(l)\n",
        "\n",
        "    data = torch.utils.data.Subset(data_train,l)\n",
        "    \n",
        "    if i == 0:\n",
        "      \n",
        "      optimizer = torch.optim.SGD(model.parameters(),lr=2,weight_decay=1e-5)\n",
        "    \n",
        "    else:\n",
        "      optimizer = torch.optim.SGD(model.parameters(),lr=2,weight_decay = 1e-5)\n",
        "    \n",
        "\n",
        "    scheduler =torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones =  [49,63], gamma=0.2, last_epoch=-1)\n",
        "    \n",
        "    dl = torch.utils.data.DataLoader(data,batch_size=128,shuffle=True)\n",
        "        \n",
        "    LR = 2\n",
        "    EPOCHS = 70\n",
        "    target_t_old = None\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "      counter = 0\n",
        "      for   images, label in (dl):\n",
        "            \n",
        "            \n",
        "            images = images.to(DEVICE)\n",
        "            \n",
        "            labels = label.to(DEVICE)\n",
        "            \n",
        "            \n",
        "            output = model(images)\n",
        "            output = output.to(DEVICE)\n",
        "            target_t_old, new_target = new_label_exemplar(label, target_prec, target_t_old, i)\n",
        "            \n",
        "            \n",
        "            target_loss = crea_target_classification(images,new_target,i)\n",
        "            target_loss = target_loss.to(DEVICE)\n",
        "\n",
        "            if model_distillation is not None:\n",
        "                output_distillation = model_distillation(images) \n",
        "                \n",
        "                label_distillation = crea_target_distillation(output_distillation)\n",
        "                \n",
        "                target_loss = crea_label_classification_distillation(label_distillation, target_loss)\n",
        "\n",
        "            loss_value = loss_function(output,target_loss)\n",
        "            if counter % 39 == 0 and counter != 0:\n",
        "              print(\"epoch:\",epoch,\"loss\",loss_value,\"lr\",scheduler.get_last_lr())\n",
        "            counter = counter + 1\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            del output\n",
        "            del images\n",
        "            del label\n",
        "\n",
        "            if model_distillation is not None:\n",
        "              del output_distillation\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "      scheduler.step()\n",
        "\n",
        "    target_prec.append(target_t_old)\n",
        "    \n",
        "    print(\"entro in modalit√† test\")\n",
        "    if model_distillation is not None:\n",
        "        del model_distillation\n",
        "        torch.cuda.empty_cache()\n",
        "        model_distillation = None\n",
        "    model.eval()\n",
        "    if test is None:\n",
        "        test = torch.utils.data.Subset(data_test,list_of_image_test[i])\n",
        "        ##creare la label per train##\n",
        "        target = [label for _, label in test]\n",
        "        _, label = new_label2(target, i*10, target_t_old)\n",
        "        test_label = test_label + label\n",
        "        accuracy_test.append(accuracy(test, model, test_label))\n",
        "        \n",
        "        m = M//(i*10+10)\n",
        "        print(\"m:\",m)\n",
        "        constructExemplar(exemplars,data_train,target_prec[i], dc,model,m)\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        subset = torch.utils.data.Subset(data_test,list_of_image_test[i])\n",
        "        test = torch.utils.data.ConcatDataset([test,subset]) \n",
        "        ###creare le label per subset###\n",
        "        target = [label for _, label in subset]\n",
        "        _, label = new_label2(target, i*10, target_t_old)\n",
        "        test_label = test_label + label\n",
        "        accuracy_test.append(accuracy(test, model, test_label))\n",
        "        \n",
        "        m = M//(i*10+10)\n",
        "        print(\"m:\",m)\n",
        "        reduceExemplars(exemplars,dc.keys(),m)\n",
        "        constructExemplar(exemplars,data_train,target_prec[i],dc,model,m)  \n",
        "    print(target_loss.size())\n",
        "    print(loss_value, epoch)\n",
        "    del target_loss\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"accuracy:\",accuracy_test[i])\n",
        "    model_distillation = copy.deepcopy(model) \n",
        "    \n",
        "    model.updatemodel()\n",
        "    print(\"modello update\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkObxtV1mnIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(accuracy_test)\n",
        "print(np.mean(accuracy_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}