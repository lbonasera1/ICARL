{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWhAZDOToWo2"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.backends import cudnn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UXC8VTKoWrc"
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.RandomCrop(32,padding=4),\n",
    "                                          torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "                                          torchvision.transforms.ToTensor()])\n",
    "\n",
    "transform1 = torchvision.transforms.Compose([torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                                      torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "                                      torchvision.transforms.ToTensor(),\n",
    "                                      torchvision.transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
    "                                                           std=[0.2673, 0.2564, 0.2761])])\n",
    "\n",
    "transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                     torchvision.transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
    "                                                          std=[0.2673, 0.2564, 0.2761])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "af1c57103a7242e9a15da0905afe63a2",
      "d347dc9462f5406f8bbc8ab6ed59d016",
      "82281bbbdb86464cb182a3ef0548313b",
      "1a2ac24fe7fe403583e1c007596d8301",
      "a92fa58285d541ed91ce774b13c9d5a3",
      "2345509e3420441380221fd2274b0d9d",
      "311aea33f4b64fc3bb2e8a9bf6f05934",
      "d4585edd2fbf48caad7d7d6a8d513d7a"
     ]
    },
    "colab_type": "code",
    "id": "yfWul7GLowgm",
    "outputId": "d0db087d-810e-49e8-9598-ce4a13e2ec0e"
   },
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.CIFAR100(root='./ICARL/data', download = True, transform = transform1, target_transform = None)\n",
    "data_test = torchvision.datasets.CIFAR100(root='./ICARL/data',train = False,download = True, transform = transform2, target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "O9SVubYloWty"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "Credits to @hshustc\n",
    "Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        self.flag = True\n",
    "        self.inplanes = 16\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        ###### self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "        self.fc = nn.ModuleList([nn.Linear(64,10)])\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def updatemodel(self):\n",
    "        self.fc.append(nn.Linear(64,10).cuda())\n",
    "\n",
    "    def set_flag(self,b):\n",
    "        self.flag = b\n",
    "      \n",
    "              \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.flag == False:\n",
    "          return x\n",
    "        else:\n",
    "          t = x\n",
    "          x = self.fc[0](x)\n",
    "          for i in range(1,len(self.fc)):\n",
    "            x = torch.cat((x,self.fc[i](t)),1)\n",
    "        return x\n",
    "\n",
    "def resnet32(pretrained=False, **kwargs):\n",
    "    n = 5\n",
    "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZsLHDO0oWwM"
   },
   "outputs": [],
   "source": [
    "def obtain_list_of_subset(seed,dataset):\n",
    "    l = list(range(0,100))\n",
    "    random.Random(seed).shuffle(l)\n",
    "    dc = {tuple(l[i:i+10]) : [] for i in range(0,100,10)}\n",
    "    for i,t in enumerate(dataset.targets):\n",
    "        \n",
    "        idx = [j for j in range(10) if  t in list(dc.keys())[j]]\n",
    "        dc[list(dc.keys())[idx[0]]].append(i)\n",
    "    return list(dc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9E05duPVpHMo"
   },
   "outputs": [],
   "source": [
    "def accuracy(test_data, model, label):\n",
    "    classi_finali = []\n",
    "    dl1 = torch.utils.data.DataLoader(test_data, batch_size = 128)\n",
    "    for input_data, _  in dl1:\n",
    "      input_data = input_data.to(DEVICE)\n",
    "      output = model(input_data)\n",
    "      del input_data\n",
    "      torch.cuda.empty_cache()\n",
    "      _, classes = torch.max(output,1)\n",
    "      del output\n",
    "      torch.cuda.empty_cache()\n",
    "      classes = classes.tolist()\n",
    "      classi_finali = classi_finali + classes\n",
    "    corretti = 0\n",
    "    for i in range(len(classi_finali)):\n",
    "        if classi_finali[i] == label[i]:\n",
    "            corretti = corretti + 1\n",
    "\n",
    "    return corretti/len(classi_finali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcz-0pKwpOEE"
   },
   "outputs": [],
   "source": [
    "def new_label_exemplar(label, target_t_prec, target_t_old, index): ### label sono le etichette del codice\n",
    "    new_target = []\n",
    "    old_class_set = set([item for sublist in target_t_prec for item in sublist])\n",
    "\n",
    "    if target_t_old is None:\n",
    "        if  not isinstance(label,list):\n",
    "            label = label.tolist()\n",
    "        target_t_old = tuple(set(label)-old_class_set)\n",
    "    \n",
    "    for i,el in enumerate(label):\n",
    "       \n",
    "        if el in target_t_old: \n",
    "            \n",
    "            new_target.append(target_t_old.index(el) + index*10)\n",
    "\n",
    "        else: \n",
    "            \n",
    "            for j,t in enumerate(target_t_prec):\n",
    "                if el in t:\n",
    "                    new_target.append(t.index(el) + (j*10))\n",
    "\n",
    "    return target_t_old,new_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elNsopAFpQ0U"
   },
   "outputs": [],
   "source": [
    "def target_for_test(label, target_t_prec, target_t_old, index):\n",
    "  new_label = []\n",
    "  \n",
    "  for i,el in enumerate(label):\n",
    "    \n",
    "       \n",
    "    if el in target_t_old: \n",
    "            \n",
    "      new_label.append(target_t_old.index(el) + index*10)\n",
    "      \n",
    "    else: \n",
    "      \n",
    "      for j,t in enumerate(target_t_prec):\n",
    "        if el in t:\n",
    "          new_label.append(t.index(el) + (j*10))\n",
    "          \n",
    "  return new_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKqa0PZhpTQ8"
   },
   "outputs": [],
   "source": [
    "def crea_target_classification(BatchDati,Target,i):\n",
    "    N = BatchDati.size(0)\n",
    "    C = i*10+10\n",
    "    NewTarget = torch.zeros(N,C)\n",
    "    for j in range(N):\n",
    "        if Target[j] >= i*10 and Target[j] < (i+1)*10:  \n",
    "            NewTarget[j,Target[j]] = 1 \n",
    "    return NewTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_CuzvOzpVU_"
   },
   "outputs": [],
   "source": [
    "def crea_target_distillation(output_distillation):\n",
    "    output_distillation = torch.sigmoid(output_distillation)\n",
    "    N = output_distillation.size(0)\n",
    "    zero_tensor = torch.zeros(N,10).to(DEVICE)\n",
    "    output_distillation = torch.cat((output_distillation, zero_tensor),1)\n",
    "    return output_distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTaQRkPTpXum"
   },
   "outputs": [],
   "source": [
    "def crea_label_classification_distillation(label_distillation, label_classification):\n",
    "    return label_distillation+label_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmSLIoOVpZae"
   },
   "outputs": [],
   "source": [
    "def take_index_for_class(data):\n",
    "    target = [el[1] for el in data]\n",
    "    target = tuple(set(target))\n",
    "    \n",
    "    dc = {k:[] for k in target}\n",
    "    for i,el in enumerate(data):\n",
    "        (dc[el[1]]).append(i)\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYDgxD6rpbYL"
   },
   "outputs": [],
   "source": [
    "def reduceExemplars(exemplars, classes, m):\n",
    "    for c in classes:\n",
    "      exemplars[c] = exemplars[c][:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOZoUo0UpdGy"
   },
   "outputs": [],
   "source": [
    "def constructExemplar(exemplars,data,classi,classindex,model,m):\n",
    "    class_means = torch.empty((0, 64)).cuda()\n",
    "    pdist = torch.nn.PairwiseDistance(p=2)\n",
    "    model.train(False)\n",
    "    model.set_flag(False)\n",
    "    with torch.no_grad():\n",
    "        model.set_flag(False)\n",
    "        print(\"classi:\",classi)\n",
    "        for c in classi:\n",
    "            print(\"classe: \",c)\n",
    "            features = torch.empty(0,64).to('cuda')\n",
    "            indexes = copy.deepcopy(classindex[c])\n",
    "            subset = torch.utils.data.Subset(data,indexes) \n",
    "            dataloader = torch.utils.data.DataLoader(subset,batch_size = 128)\n",
    "\n",
    "            for image, label in dataloader:\n",
    "                image = image.to(DEVICE)\n",
    "                output = model(image)\n",
    "                output = nn.functional.normalize(output, p=2, dim=1)\n",
    "                features = torch.cat((features,output))\n",
    "                \n",
    "            \n",
    "            class_mean = torch.mean(features, 0)\n",
    "            class_mean = nn.functional.normalize(class_mean, p=2, dim=0)\n",
    "            class_mean = class_mean.view(-1, 64)\n",
    "            class_means = torch.cat((class_means, class_mean))\n",
    "            current_features = torch.empty((0, 64)).cuda()\n",
    "            exemplars_indexes = []\n",
    "            for k in range(m):\n",
    "              current_sum = torch.sum(current_features, 0)\n",
    "              current_sum = torch.add(features, current_sum.repeat(features.size(0), 1))\n",
    "              current_mean = current_sum * (1.0/(k+1))\n",
    "              current_mean = nn.functional.normalize(current_mean, p=2, dim=1)\n",
    "              distances = pdist(current_mean, class_mean)\n",
    "              # collecting chosen features\n",
    "              index = torch.argmin(distances).item()\n",
    "              phi = features[index].view(-1, 64)\n",
    "              current_features = torch.cat((current_features, phi))\n",
    "              # removing chosen features\n",
    "              features = torch.cat((features[:index], features[index+1:]))\n",
    "              exemplars_indexes.append(indexes.pop(index)) \n",
    "            exemplars[c] = exemplars_indexes\n",
    "    model.set_flag(True)\n",
    "    return class_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-ZEges7pfyl"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIn04INhOEel"
   },
   "outputs": [],
   "source": [
    "def classifierNCM(train_dataset,input_image, exemplars, labels_old, labels_new, class_means, model,indexofit):\n",
    "  pdist = nn.PairwiseDistance(p=2)\n",
    "  lbls_old = [item for sublist in labels_old for item in sublist]\n",
    "  model.train(False)\n",
    "  model.set_flag(False)\n",
    "  with torch.no_grad():\n",
    "    tensor = torch.zeros((input_image.size(0), (indexofit+1)*10), device=\"cuda:0\")\n",
    "    exemplars_mean = torch.empty((0, 64)).cuda()\n",
    "    for c in lbls_old:\n",
    "      l1 = list(exemplars[c])\n",
    "      subset = torch.utils.data.Subset(train_dataset, l1)\n",
    "      dataLoader = torch.utils.data.DataLoader(subset, batch_size=128)\n",
    "      mean = torch.empty((0, 64)).cuda()\n",
    "      for image, label in dataLoader:\n",
    "        image = image.to(DEVICE)\n",
    "        output = model(image)\n",
    "        # L2 normalization of feature vector\n",
    "        output = nn.functional.normalize(output, p=2, dim=1)\n",
    "        mean = torch.cat((mean, output))\n",
    "      mean = torch.mean(mean, 0)\n",
    "      mean = nn.functional.normalize(mean, p=2, dim=0)\n",
    "      mean = mean.view(-1, 64)\n",
    "      exemplars_mean = torch.cat((exemplars_mean, mean))\n",
    "\n",
    "    exemplars_mean = torch.cat((exemplars_mean, class_means))\n",
    "    classes = list(lbls_old) + list(labels_new)\n",
    "\n",
    "    output = model(input_image)\n",
    "    output = nn.functional.normalize(output, p=2, dim=1)\n",
    "    for n in range((output.size(0))):\n",
    "      image = output[n]\n",
    "      distances = pdist(image, exemplars_mean)\n",
    "      index = torch.argmin(distances).item()\n",
    "      index = target_for_test([classes[index]], labels_old, labels_new, indexofit)\n",
    "      index = index[0]\n",
    "      tensor[n][index] = 1\n",
    "\n",
    "  model.set_flag(True)\n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dvPk3yKplLv"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "model_distillation = None\n",
    "DEVICE = 'cuda'\n",
    "test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0VQRi9A7pngC",
    "outputId": "069a1767-bd6e-4da8-f9c0-8826040fac54"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=5000)\n",
    "import random\n",
    "if model is not None:\n",
    "  del model\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "if model_distillation is not None: \n",
    "  del model_distillation\n",
    "  torch.cuda.empty_cache()\n",
    "  model_distillation = None\n",
    "\n",
    "from torch.backends import cudnn\n",
    "DEVICE = 'cuda'\n",
    "model = resnet32()\n",
    "model = model.to(DEVICE)\n",
    "cudnn.benchmark\n",
    "\n",
    "list_of_image = obtain_list_of_subset(1994,data_train)\n",
    "list_of_image_test = obtain_list_of_subset(1994,data_test)\n",
    "dc = take_index_for_class(data_train)\n",
    "test = None\n",
    "test_label = []\n",
    "accuracy_test = []\n",
    "exemplars = [[] for x in range(100)]\n",
    "target_prec = []\n",
    "M = 2000\n",
    "for i in range(10):\n",
    "    a = set(([item for sublist in exemplars for item in sublist]))\n",
    "    somma= sum([1 for el in  a])\n",
    "    print(\"num exemplari:\",somma)\n",
    "    l = list_of_image[i]+[item for sublist in exemplars for item in sublist]\n",
    "    random.Random(35).shuffle(l)\n",
    "\n",
    "    data = torch.utils.data.Subset(data_train,l)\n",
    "    \n",
    "    if i == 0:\n",
    "      \n",
    "      optimizer = torch.optim.SGD(model.parameters(),lr=2,weight_decay=1e-5)\n",
    "    \n",
    "    else:\n",
    "      optimizer = torch.optim.SGD(model.parameters(),lr=2,weight_decay = 1e-5)\n",
    "    \n",
    "\n",
    "    scheduler =torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [49,63], gamma=0.2, last_epoch=-1)\n",
    "    \n",
    "    dl = torch.utils.data.DataLoader(data,batch_size=128,shuffle=True)\n",
    "        \n",
    "    LR = 2.0\n",
    "    EPOCHS = 70\n",
    "    target_t_old = None\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "      model.train()\n",
    "      counter = 0\n",
    "        \n",
    "      for   images, label in (dl):\n",
    "            \n",
    "            \n",
    "            images = images.to(DEVICE)\n",
    "            \n",
    "            labels = label.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            output = output.to(DEVICE)\n",
    "            \n",
    "            target_t_old, new_target = new_label_exemplar(label, target_prec, target_t_old, i)\n",
    "            STAMPA = False\n",
    "            \n",
    "            target_loss = crea_target_classification(images,new_target,i)\n",
    "            target_loss = target_loss.to(DEVICE)\n",
    "\n",
    "            if model_distillation is not None:\n",
    "                model_distillation.eval() \n",
    "                output_distillation = model_distillation(images)\n",
    "                \n",
    "                label_distillation = crea_target_distillation(output_distillation)\n",
    "                \n",
    "                target_loss = crea_label_classification_distillation(label_distillation, target_loss)\n",
    "\n",
    "            loss_value = loss_function(output,target_loss)\n",
    "            if counter % 39 == 0 and counter != 0:\n",
    "              print(\"epoch:\",epoch,\"loss\",loss_value,\"lr\",scheduler.get_last_lr())\n",
    "            counter = counter + 1\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            del output\n",
    "            del images\n",
    "            del label\n",
    "\n",
    "            if model_distillation is not None:\n",
    "              del output_distillation\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "      scheduler.step()\n",
    "\n",
    "    \n",
    "    print(\"entro in modalità test\")\n",
    "    if model_distillation is not None:\n",
    "        del model_distillation\n",
    "        torch.cuda.empty_cache()\n",
    "        model_distillation = None\n",
    "    model.eval()\n",
    "    if test is None:\n",
    "        test = torch.utils.data.Subset(data_test,list_of_image_test[i])\n",
    "        m = M//(i*10+10)\n",
    "        print(\"m:\",m)\n",
    "        \n",
    "        class_means = constructExemplar(exemplars,data_train,target_t_old, dc,model,m)\n",
    "\n",
    "        dltest = torch.utils.data.DataLoader(test,batch_size=128, shuffle=False, num_workers=4)\n",
    "        \n",
    "        running_corrects = 0\n",
    "        STAMPA = True\n",
    "        for images, labels in dltest:\n",
    "          with torch.no_grad():\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = classifierNCM(data_train,images, exemplars, target_prec, target_t_old, class_means, model,i)\n",
    "            STAMPA = False\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            labels = target_for_test(labels, target_prec, target_t_old, i)\n",
    "            for idx in range(len(labels)):\n",
    "              if preds[idx] == labels[idx]:\n",
    "                running_corrects = running_corrects + 1\n",
    "        score = running_corrects / float(len(test))\n",
    "        accuracy_test.append(score)\n",
    "    else:\n",
    "        \n",
    "        subset = torch.utils.data.Subset(data_test,list_of_image_test[i])\n",
    "        test = torch.utils.data.ConcatDataset([test,subset])\n",
    "        m = M//(i*10+10)\n",
    "        print(\"m:\",m)\n",
    "        reduceExemplars(exemplars,dc.keys(),m)\n",
    "        class_means = constructExemplar(exemplars,data_train,target_t_old,dc,model,m)\n",
    "        dltest = torch.utils.data.DataLoader(test,batch_size=128, shuffle=False, num_workers=4)\n",
    "        running_corrects = 0\n",
    "        STAMPA = True\n",
    "        for images, labels in dltest:\n",
    "          with torch.no_grad():\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = classifierNCM(data_train,images, exemplars, target_prec, target_t_old, class_means, model,i)\n",
    "            STAMPA = False\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            labels = target_for_test(labels, target_prec, target_t_old, i)\n",
    "            for idx in range(len(labels)):\n",
    "              if preds[idx] == labels[idx]:\n",
    "                running_corrects = running_corrects + 1\n",
    "\n",
    "        score = running_corrects / float(len(test))\n",
    "        accuracy_test.append(score)\n",
    "\n",
    "\n",
    "       \n",
    "    print(target_loss.size())\n",
    "    print(loss_value, epoch) \n",
    "    del target_loss\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"accuracy:\",accuracy_test[i])\n",
    "    model_distillation = copy.deepcopy(model) \n",
    "    target_prec.append(target_t_old)\n",
    "    model.updatemodel()\n",
    "    print(\"model update\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "icarlrisultati2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a2ac24fe7fe403583e1c007596d8301": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4585edd2fbf48caad7d7d6a8d513d7a",
      "placeholder": "​",
      "style": "IPY_MODEL_311aea33f4b64fc3bb2e8a9bf6f05934",
      "value": " 169009152/? [00:20&lt;00:00, 81186455.55it/s]"
     }
    },
    "2345509e3420441380221fd2274b0d9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "311aea33f4b64fc3bb2e8a9bf6f05934": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82281bbbdb86464cb182a3ef0548313b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2345509e3420441380221fd2274b0d9d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a92fa58285d541ed91ce774b13c9d5a3",
      "value": 1
     }
    },
    "a92fa58285d541ed91ce774b13c9d5a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "af1c57103a7242e9a15da0905afe63a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_82281bbbdb86464cb182a3ef0548313b",
       "IPY_MODEL_1a2ac24fe7fe403583e1c007596d8301"
      ],
      "layout": "IPY_MODEL_d347dc9462f5406f8bbc8ab6ed59d016"
     }
    },
    "d347dc9462f5406f8bbc8ab6ed59d016": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4585edd2fbf48caad7d7d6a8d513d7a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
